# WIKIPEDIA ANALYSIS

## Wikipedia offers rich set of data that is easily and readily available for data scientists. The data from Wiki can be used to practice the science of Big Data Analytics
## This project addresses the following questions about Wiki. The data is obtained from Wiki dumps. https://dumps.wikimedia.org/ 

Which English wikipedia article got the most traffic on January 20, 2021?

What English wikipedia article has the largest fraction of its readers follow an internal link to another wikipedia article?

What series of wikipedia articles, starting with Hotel California, keeps the largest fraction of its readers clicking on internal links? This is similar to (2), but you should continue the analysis past the first article. There are multiple ways you can count this fraction, be careful to be clear about the method you find most appropriate.

Find an example of an English wikipedia article that is relatively more popular in the Americas than elsewhere. There is no location data associated with the wikipedia pageviews data, but there are timestamps. You'll need to make some assumptions about internet usage over the hours of the day.

Analyze how many users will see the average vandalized wikipedia page before the offending edit is reversed.
Run an analysis you find interesting on the wikipedia datasets we're using.


## Technologies Used

* Scala 2.11.12 for developing code
* Java 8, JVM
* Hadoop 
* YARN
* HDFS
* HIVE
* PostgreSQL
* DBeaver DB client
* Beeline DB Client

## Features

List of features ready and TODOs for future development
* Hive Tables to hold ClickStream Data for the date range of Jan 19 to Jan 20, 2021
* Hive Tables to hold PageView Data


